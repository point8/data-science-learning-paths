{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Graph Data in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we introduce another form of data that is increasingly relevant to data analysis applications: Graph data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graphics/third-party/graph-example.png) _Source: [Wilson Mar: Graph Database Introduction](https://wilsonmar.github.io/neo4j/https://wilsonmar.github.io/neo4j/)_ \n",
    "\n",
    "A **graph** is a mathematical representation of a **network**: A set of **nodes** (or **vertices**) connected by a set of **edges** (or **links**). Nodes can represent any kind of entity, while edges represent relationships between entities. Both nodes and edges can have attached attributes. \n",
    "\n",
    "To introduce the concept, let's have a look at some graph data representing a **social network**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = [\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 30),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 36),\n",
    "  (\"g\", \"Gabby\", 60), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_data = [\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\"),\n",
    "  (\"g\", \"a\", \"follow\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this small data example where performance does not matter, we use `pandas`, `matplotlib` and the **graph library** [`NetworkX`](http://networkx.github.io) to assemble and visualize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_frame = pandas.DataFrame(\n",
    "    node_data,\n",
    "    columns=[\"id\", \"name\", \"age\"],\n",
    ").set_index(\"id\")\n",
    "node_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_frame = pandas.DataFrame(\n",
    "    edge_data,\n",
    "    columns=[\"source\", \"target\", \"relationship\"]\n",
    ")\n",
    "edge_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct the graph using a graph data structure from `NetworkX`. The data contains a **directed graph** - an edge has a specific direction from a source to a target node. **Undirected** graphs, in which the direction of the relationship does not matter, also exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = networkx.DiGraph() # directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in node_frame.iterrows():\n",
    "    graph.add_node(i, **row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in edge_frame.iterrows():\n",
    "    graph.add_edge(row[\"source\"], row[\"target\"], relationship=row[\"relationship\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a graph layout algorithm calculates positions of the nodes so that the graph is well-arranged and readable in a drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = networkx.spring_layout(graph)\n",
    "networkx.draw_networkx_nodes(graph, pos, cmap=plt.get_cmap('jet'), node_size = 500)\n",
    "networkx.draw_networkx_labels(graph, pos)\n",
    "networkx.draw_networkx_edges(graph, pos, arrows=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Data in Spark with GraphFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While libraries like `NetworkX` can deal with graph data sets of thousands of nodes and edges in memory, interesting graphs can be in the billions of nodes and edges: Consider for example the **web graph** of all web pages connected by hyperlinks. For dealing with massive graphs, distributed systems for graph processing have been developed, also on the basis of Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**GraphX**](http://spark.apache.org/graphx/) is the official Apache Spark component for handling graph data. As of now however, the GraphX API is not available in PySpark. We therefore rely on an external package, **[`GraphFrames`](https://github.com/graphframes/graphframes)** that aims to combine the advantages of Spark DataFrames and GraphX algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During creation of the Spark SQL session we configure PySpark to use an external package for GraphFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession \\\n",
    "                    .builder \\\n",
    "                    .appName(\"Graph Frames Test\") \\\n",
    "                    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.0-spark3.0-s_2.12\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can now be assembled from two DataFrames: One for the set of nodes (with attributes) and one for the set of edges (defined by source node, target node and attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_frame = spark.createDataFrame(\n",
    "    node_data, \n",
    "    [\"id\", \"name\", \"age\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_frame = spark.createDataFrame(\n",
    "    edge_data,\n",
    "    [\"src\", \"dst\", \"relationship\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphframes.GraphFrame(node_frame, edge_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vertices` and `edges` attributes point to regular Spark SQL DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.vertices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges.filter(\"relationship = 'follow'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GraphFrames` also exposes a set of parallelized [graph algorithms](https://graphframes.github.io/graphframes/docs/_site/user-guide.html). Take for instance the calculation of **node degree** - the number of in- or outgoing edges attached to a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.inDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.outDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.degrees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another frequently needed set of algorithms are for **traversal** or **search** of the graph. This method performs **breadth-first search**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredPaths = graph.bfs(\n",
    "    fromExpr = \"name = 'Esther'\",\n",
    "    toExpr = \"age < 32\",\n",
    "    edgeFilter = \"relationship != 'friend'\",\n",
    "    maxPathLength = 3\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the more complex graph analytics algorithms we find **PageRank** - the algorithm that made Google's search engine famous. It outputs a **centrality score** for each node, quantifying the importance of nodes by their position in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = graph.pageRank(resetProbability=0.15,  maxIter=5)\n",
    "result.vertices.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also get an API for filtering the graph data by attributes, for example for creating a **subgraph** of specific nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_friends_graph = graph\\\n",
    "    .filterEdges(\"relationship = 'friend'\")\\\n",
    "    .filterVertices(\"age > 30\")\\\n",
    "    .dropIsolatedVertices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_friends_graph.edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-ended Exercise: Understanding the GitHub Developers Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise, consider the following real-world graph data set: The network of GitHub accounts, with edges showing who follows who.\n",
    "\n",
    "- Use Spark SQL and GraphFrames to parse the CSV data into a Graph object\n",
    "- Perform exploratory data analysis to understand the properties of the graph\n",
    "- Can you determine which account has the largest followership?\n",
    "- Who is the most important developer on GitHub? And by which measure?\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../.assets/data/github_network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Graph Analysis with GraphFrames](https://docs.databricks.com/spark/latest/graph-analysis/graphframes/graph-analysis-tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
