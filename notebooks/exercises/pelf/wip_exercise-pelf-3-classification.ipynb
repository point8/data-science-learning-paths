{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Machine Learning\n",
    "\n",
    "After we prepared our data and did some feature engineering, we can try to use a machine learning algorithm to predict the target feature (direction) based on the train features (brightness and motor speed).\n",
    "\n",
    "First we have to do the module and data imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH_INTERMEDIATE = \"../../.assets/data/pelf/temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(DATAPATH_INTERMEDIATE, \"data_total_normalized.pkl.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the size of the data\n",
    "Calculating the following algorithms on the whole dataset would take a long time. We will reduce the dataset by half. There are still around 100.000 data points to look at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test set\n",
    "\n",
    "When using machine learning, you will usually divide your dataset into two subsets. The first subset is called \"training set\" and will be used to fit the model. The second subset is called \"test set\" and will be used to validate the predictions of the model on a set of data the model did not use for fitting.\n",
    "\n",
    "Here we collect the different column name which we want to use for the modelling. One contains the columns for the feature averages, the other all feature averages without the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [name for name in df.columns if (\"brightness\" in name) | (\"motor\" in name)]\n",
    "target = [\"direction_S\", \"direction_N\", \"direction_E\", \"direction_W\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use different sizes of fit and train set, however we will use a split of 90% train and 10% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.1, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the column names defined above to select the relevant columns. We also store the x-y positions for later investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "As a first exampe we use a decision tree classifier, which uses a chain of decisions on different columns to arrive at a prediction. (e.g. val>0.5 or val <=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 10\n",
    "\n",
    "DTR = DecisionTreeClassifier(max_depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = DTR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first metric we can look at is the pure accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a high accuracy and looks already very good. Let us try some other validation techniques like the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test.values.argmax(axis=1), predicted_y.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the diagonal are the correct predictions and the other values show how many predictions are wrong.\n",
    "\n",
    "These are suprisingly good results. If the depth is being reduced however, we see a strong decrease in performance, as the tree is too shallow to resolve the differences necessary for an accurate assignment of the different directions.\n",
    "\n",
    "Let us check where the incorrect cases are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_correct = X_test[(y_test == predicted_y).sum(axis=1) == 4]\n",
    "X_test_incorrect = X_test[(y_test == predicted_y).sum(axis=1) != 4]\n",
    "\n",
    "df_correct = df[df.index.isin(X_test_correct.index)]\n",
    "df_incorrect = df[df.index.isin(X_test_incorrect.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(df_correct[\"x_measured\"].values, df_correct[\"y_measured\"].values,marker=\".\",color=\"blue\")\n",
    "plt.scatter(df_incorrect[\"x_measured\"].values, df_incorrect[\"y_measured\"].values,marker=\"^\",color=\"red\",label=\"Failure\")\n",
    "plt.legend()\n",
    "plt.title(f\"Performance of the decision tree with depth: {depth}\")\n",
    "plt.xlabel(\"Relative X-Position\",fontsize=20)\n",
    "plt.ylabel(\"Relative Y-Position\",fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "An important aspect of decision trees is the importance of the features, which the DT uses to assign any value to a data point. Looking into these can (but not necessarily will) yield understanding into possible correlations between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df[\"Col_name\"] = X_test.columns\n",
    "feature_importance_df[\"Col_weight\"] = DTR.feature_importances_\n",
    "feature_importance_df.sort_values(\"Col_weight\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have tested the whole procedure for one combination of test and train set. This brings some troubles:\n",
    "\n",
    "What if we have selected a train set with a certain bias? Then we will have a (strongly) varying performance of the predictor.\n",
    "\n",
    "To rule this out, we will try to do a so called \"Cross-Validation\". The dataset is split into X evenly sized subsets (X-fold validation, here X=5), from which X-1 sets will be used for training and the remaining set is used for testing. By using this method we can extinguish the risk of randomly choosing a very good or very bad training/test split.\n",
    "\n",
    "The output of the function given here depicts the X pure accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(DTR, df[features], df[target], cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now tells us something about the average accuracy of the model in general (within the settings of the model). A high variance in the scores would be a reason to investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Now we can use other Classifiers to see if the results differ. The Random Forest Classifier uses many uncorrelated decision tree algorithms, which where fitted under some kind of randomization. The decision of the forest is then typically decided by a majority vote of the trees (if you are not interested in the class probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 20\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the accuracy score and the confusion matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = RFC.predict(X_test)\n",
    "metrics.accuracy_score(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test.values.argmax(axis=1), predicted_y.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_correct = X_test[(y_test == predicted_y).sum(axis=1) == 4]\n",
    "X_test_incorrect = X_test[(y_test == predicted_y).sum(axis=1) != 4]\n",
    "\n",
    "df_correct = df[df.index.isin(X_test_correct.index)]\n",
    "df_incorrect = df[df.index.isin(X_test_incorrect.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(df_correct[\"x_measured\"].values, df_correct[\"y_measured\"].values,marker=\".\",color=\"blue\")\n",
    "plt.scatter(df_incorrect[\"x_measured\"].values, df_incorrect[\"y_measured\"].values,marker=\"^\",color=\"red\",label=\"Failure\")\n",
    "plt.legend()\n",
    "plt.title(f\"Performance of the Random Forest Classifier with {n_est} estimators\")\n",
    "plt.xlabel(\"Relative X-Position\",fontsize=20)\n",
    "plt.ylabel(\"Relative Y-Position\",fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Neighbours\n",
    "\n",
    "We can also use the K-Neighbours Classifier, which maps all the data into a high-dimensional space (the fitting). When the model is given a new data point to predict, it also maps this point into the high-dimensional space and calculates which target class the k nearest neighbours have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = KNN.predict(X_test)\n",
    "metrics.accuracy_score(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test.values.argmax(axis=1), predicted_y.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_correct = X_test[(y_test == predicted_y).sum(axis=1) == 4]\n",
    "X_test_incorrect = X_test[(y_test == predicted_y).sum(axis=1) != 4]\n",
    "\n",
    "df_correct = df[df.index.isin(X_test_correct.index)]\n",
    "df_incorrect = df[df.index.isin(X_test_incorrect.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(df_correct[\"x_measured\"].values, df_correct[\"y_measured\"].values,marker=\".\",color=\"blue\")\n",
    "plt.scatter(df_incorrect[\"x_measured\"].values, df_incorrect[\"y_measured\"].values,marker=\"^\",color=\"red\",label=\"Failure\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance of the KNN classifier\")\n",
    "plt.xlabel(\"Relative X-Position\",fontsize=20)\n",
    "plt.ylabel(\"Relative Y-Position\",fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright Â© 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
