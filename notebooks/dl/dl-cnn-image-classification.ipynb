{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter is about a very successful technique for image processing with neuronal networks: **convolution**. We are going to walk through\n",
    "- how convolution works\n",
    "- why convolutional neural networks are so promising for image processing\n",
    "- what layers a convolutional neural network is built from and how they work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_science_learning_paths\n",
    "data_science_learning_paths.setup_plot_style(dark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Convolution?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into the mathematical definition of convolution, and how it can be done with neural networks, we start with an example from image processing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"graphics/cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((w // 2, h // 2))\n",
    "img = img.convert(\"L\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cat picture is nothing but another tensor/array, containing grayscale pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a = numpy.array(img)\n",
    "img_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.histplot(img_a.flatten(), kde=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second ingredient for the convolution is called **kernel**, **filter**, or **convolution matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = numpy.array(\n",
    "    [\n",
    "        [1, 0, -1],\n",
    "        [2, 0, -2],\n",
    "        [1, 0, -1]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular kind of kernel is well-known and has a name - the [**Sobel operator**](https://en.m.wikipedia.org/wiki/Sobel_operator). We will see what it does in a minute.\n",
    "\n",
    "During the convolution, the kernel is shifted over the pixels of the the image to transform it into a new image. The entries in the matrix define how a new pixel value results from the values of neighboring pixels. Mathematically, the new pixel results from _matrix multiplication_ of the kernel with the part of the image that it covers at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scipy` library has a function to perform this operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a_conv = convolve2d(img_a, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.histplot(img_a_conv.flatten(), kde=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the new image after convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(w // 100, h // 100))\n",
    "plt.imshow(img_a_conv, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is a _vertical edge detector_. As you may guess, the transposed kernel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(w // 100, h // 100))\n",
    "plt.imshow(\n",
    "    convolve2d(img_a, kernel.transpose()),\n",
    "    cmap=\"gray\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... does horizontal edge detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an idea of how convolution works, we combine it with machine learning. The essential trick: **The filters - that is, the entries of the convolution matrix moved over the image - are no longer predefined, but can be learned by a neural network during the training process.** \n",
    "\n",
    "A convolutional neural network architecture can take advantage of the **hierarchical patterns** in an image by extracting them layer by layer: To say it in a simplified way, the first convolution detects edges, the next one detects shapes, and so on, until an object can be detected and classified.\n",
    "\n",
    "To dig deeper into what a CNN sees, it is actually possible to visualize the activations on each layer. Here is an example where the first layers are apparently edge detectors. The deeper we go, the more abstract patterns emerge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graphics/cnn_feature_viz.jpg)\n",
    "\n",
    "[_Source_](https://www.researchgate.net/publication/319622441_DeepFeat_A_Bottom_Up_and_Top_Down_Saliency_Model_Based_on_Deep_Features_of_Convolutional_Neural_Nets/figures?lo=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ... and their Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other neural networks, convolutional architectures are composed of layers. We introduce two new layer types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Convolution2D`**: This layer performs convolution over the two-dimensional input tensor (for example, the input image). As in the example above, a kernel is shifted over the image, but this time, the entries in the convolution matrix are learnable parameters.\n",
    "\n",
    "![](graphics/conv_layer_anim.gif)\n",
    "\n",
    "In order to extract features from the image, it makes sense to perform multiple convolutions with different kernels over the same input (think vertical plus horizontal edge detection..). \n",
    "\n",
    "This brings us to the two most important parameters of this layer:\n",
    "\n",
    "- `filters`: the number of convolutions performed over the input\n",
    "- `kernel_size`: the shape of the convolution matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MaxPooling2D`**: This layer reduces the size of the input by looking at a certain window and selecting only the maximum value. This way, **the max-pooling operator performs de-noising as well as dimensionality reduction.**\n",
    "\n",
    "![](graphics/pooling_layer_anim.gif)\n",
    "\n",
    "It has one main parameter:\n",
    "\n",
    "- `pool_size`: the shape of the pooling window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a convolutional layer is  followed by a pooling layer in a CNN. It is typical to stack several of these convolution/pooling pairs to make the network deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CNN Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CNN Explainer](https://github.com/poloclub/cnn-explainer) is a great open-source demo of a convolutional architecture for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<iframe src=https://poloclub.github.io/cnn-explainer/ width=100% height=800></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Classification with a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to revisit the digit classification problem, but this time we try a convolutional architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
    "input_shape = (img_size, img_size, 1)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = numpy.expand_dims(X_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "\n",
    "In the following we are going to train a network with the following convolutional architecture: Two sets of convolution/max pooling layers are followed by a flattening operator, a fully-connected layer and an output layer with ten neurons for digit classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graphics/convnet_architecture.jpg)\n",
    "\n",
    "_[Source](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 4    # number of filters in first convolutional layer\n",
    "n2 = 8   # number of filters in second convolutoinal layer\n",
    "n3 = 16   # number of neurons in final dense layer\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "net = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(\n",
    "            filters=n1,\n",
    "            kernel_size=(3,3),\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2)\n",
    "        ),\n",
    "        keras.layers.Conv2D(\n",
    "            filters=n2,\n",
    "            kernel_size=(3,3),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2)\n",
    "        ),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(\n",
    "            units=n3,\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            units=n_classes,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise: Train and Evaluate the CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2026 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
