{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling the Learning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we \n",
    "- observe the training progress of a neural network model\n",
    "- recognize and diagnose unwanted situations during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo: Learning Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [TensorFlow Playground](https://playground.tensorflow.org/) provides an interactive demo of a simple neural network for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<iframe src=https://playground.tensorflow.org/ width=100% height=700></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-In and Custom Losses\n",
    "\n",
    "During training, a **loss function** or **objective function** is optimized. As discussed in previouschapters, choosing an appropriate criterion to optimize is an essential step in any machine learning process.\n",
    "\n",
    "`keras` provides a few common losses as built-in functions, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.losses.mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the desired loss function is not there, it is straightforward to implement it efficiently with `tensorflow` operations: Here is the **Root Mean Squared Error** for two vectors $y$ and $\\hat{y}$:\n",
    "\n",
    "$$R M S E(y, \\hat{y}) =\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-{\\hat{y}}_{i}\\right)^{2}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return keras.backend.sqrt(\n",
    "            keras.backend.mean(\n",
    "                keras.backend.square(y_pred - y_true)\n",
    "            )\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Training History "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Loss\n",
    "\n",
    "Training loss is almost always smaller than validation loss, since the model has had a chance to see the training data already. However, validation loss should follow closely - if there is a large gap, this is  a sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwanted Situations and Remedies\n",
    "\n",
    "**Overfitting through Overtraining**\n",
    "\n",
    "Observing the training loss and validation loss curves, we frequently encounter the following picture with prolonged training:\n",
    "\n",
    "![](https://i.stack.imgur.com/1QU0m.png)\n",
    "\n",
    "Training and validation loss decrase together until a certain number of epochs, where validation loss increases again while training loss continues to decrease. This is an indication of **overfitting** caused by adapting the weights too strongly to the training set. This results in a loss of generalization power. \n",
    "\n",
    "Clearly this can be avoided by stopping the training process at the right time, when a minimum in validation loss is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Stopping\n",
    "\n",
    "Rather than estimating the number of epochs, we can rely on `keras` callbacks to monitor our target function and stop the training when no more significant improvement is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.callbacks.EarlyStopping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Automatic Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we configure the training process to stop if the accuracy on the validation set does not improve much for several epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
    "input_shape = (img_size, img_size, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 8    # number of filters in first convolutional layer\n",
    "n2 = 16   # number of filters in second convolutoinal layer\n",
    "n3 = 16   # number of neurons in final dense layer\n",
    "\n",
    "net = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Convolution2D(\n",
    "            input_shape=input_shape,\n",
    "            filters=n1,\n",
    "            kernel_size=(5,5),\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2)\n",
    "        ),\n",
    "        keras.layers.Convolution2D(\n",
    "            filters=n2,\n",
    "            kernel_size=(5,5),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2)\n",
    "        ),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(\n",
    "            units=n3,\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            units=n_classes,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    verbose=True,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            min_delta=0.01,\n",
    "            patience=3,\n",
    "            verbose=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright Â© 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
