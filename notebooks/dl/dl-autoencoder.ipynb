{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **autoencoder** is a neural network with the task of reconstructing its own input. \n",
    "\n",
    "The network architecture is composed of two parts - the **encoder** and the **decoder**. It can be thought of as having a bowtie shape.\n",
    "\n",
    "![autencoder](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Autoencoder_schema.png/528px-Autoencoder_schema.png)\n",
    "\n",
    "The input is a data vector of dimension $n$ that is given to an **input layer**. It is then processed through one or more layers until it arrives at a **hidden layer** with fewer neurons, which gives a vector of dimension $k < n$ - this part of the network is the **encoder** part.\n",
    "\n",
    "The following layers comprise the **decoder**. It receives the vector of size $k$ as input and is trained to reconstruct the original input from that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to see how to construct and train an autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the MNIST dataset in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since neural networks are sensitive to the scale of the input values, we start by scaling all pixel values to the interval $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key property of our network architecture is the size of the latent layer: The number of neurons in this \"bottleneck\" layer determines how much of a dimensionality reduction is going to happen and how difficult it will be for the decoder to reconstruct the image.\n",
    "\n",
    "We start with a guess of 32 neurons in the latent layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 28\n",
    "input_dim = img_width * img_width\n",
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the following architecture for the encoder part of the network:\n",
    "\n",
    "* a `Flatten` layer turns the image into a 1-dimensional vector of $n$ grayscale values \n",
    "* two `Dense` layers implement the reduction from $n$ to $k$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layers = [\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(input_dim, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(latent_dim, activation='relu')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decoder part, we add:\n",
    "* another `Dense` layer that expands the $k$ latent values back to $n$ values\n",
    "* a `Reshape` layer undos the `Flatten` operation and outputs a 2-dimensional image again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layers = [\n",
    "    keras.layers.Dense(input_dim, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape((28,28))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assemble encoder and decoder layers into a sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.Sequential(encoder_layers + decoder_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled with the _Mean Squared Error_ as a loss function, since our objective is to minimize the difference between the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to training: Since an autoencoder learns the _identity_ function - that is, a function where input and output are the same - the feature and target tensors we pass are one and the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    X_train, \n",
    "    X_train, \n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training is finished, we feed the test set of images to the autoencoder in order to see if it can accurately reconstruct the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    f, axarr = plt.subplots(nrows=1, ncols=2)\n",
    "    axarr[0].imshow(X_test[i], cmap=\"binary\")\n",
    "    axarr[1].imshow(decoded[i], cmap=\"binary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Experiment with the Architecture\n",
    "\n",
    "Try experimenting with the autoencoder's network architecture. In particular, try to change the size of the latent layer. Can you minimize it? Can you achieve a good encoding performance with fewer neurons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Fashion Autoencoder\n",
    "\n",
    "Try building an autoencoder for the _Fashion MNIST_ dataset!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright Â© 2018-2022 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
