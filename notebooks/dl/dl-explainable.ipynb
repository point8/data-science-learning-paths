{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable Networks\n",
    "\n",
    "> What do you call it if someone has absolute faith in artificial intelligence?  - [Naive bias](https://en.m.wikipedia.org/wiki/Naive_Bayes_classifier).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network models have acquired a reputation for being **black boxes** - they make accurate decisions, but we have a hard time explaining what actually influenced the decisions.  This can be an obstacle to the deployment of such models, when its decisions need to be transparent to enable technical, ethical or legal review. The field of **explainable artificial intelligence** aims to remedy this problem. In the following we are going to look at an algorithm that aims to explain predictions in image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Clever Hans\n",
    "\n",
    "But first let me tell you the story of **Clever Hans**: _Der Kluge Hans_ was a trained horse that made headlines in Germany 1904 due to his amazing intelligence. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Osten_und_Hans.jpg/640px-Osten_und_Hans.jpg)\n",
    "\n",
    "During demonstrations, Hans was seemingly able to count and arithmetic exercises and answered correctly to the questions of the trainer, a mathematics teacher, by tapping his hooves or shaking his head. Scientists were puzzled. Eventually, a student solved the mystery: He was able to demonstrate that Clever Hans had no concept of mathematics, but was able to pick up on very subtle cues in the body language of the human posing the task. That allowed Hans to detect the right answer for about 90% of the questions.\n",
    "\n",
    "Ever since then, research in animal cognition is wary of the **Clever Hans effect**, where the animal trainer unwittingly provides cues that are correlated with the right answer.  A similar phenomenon can happen when training machine learning systems:  Rather than learning a generalizable concept, the machine learning model is trained to pick up on _spurious correlations_ of the input data with the correct answer. [Ribeiro et al. ]() provide a practical example for this: An image classifier mislabels a picture of a husky as a wolf, even though the classifier was shown to have high accuracy during model engineering. Using the LIME algorithm - which we will introduce shortly - the authors are able to show the spurious correlation that the model used: Apparently the training images for \"wolf\" had snow in them.\n",
    "\n",
    "![](graphics/husky-wolf.png)\n",
    "\n",
    "\n",
    "This is related to the problem of **leakage** - _leaking_ the label to the classifier, allowing it to cheat. Leakage can be difficult to detect and requires careful cleaning of the data to avoid. A classifier performance that is \"too good to be true\" is often a sign of leakage. \n",
    "\n",
    "How can we gain more certainty about what the ML model reacts to? An analysis of [üììFeature Importance](../ml/ml-feature-engineering.ipynb) can give us insights. Inspecting deep learning models with very high-dimensional inputs is more challenging, but there are algorithmic approaches that can help.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model: Inception V3 for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Inception V3](https://keras.io/applications/#inceptionv3) is a deep convolutional neural network architecture for image classification. A model trained on 1000 classes from the [ImageNet](ImageNet) benchmark data set is provided with `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = inception_v3.InceptionV3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the Inception network classifies several animal photos. We need to do some preprocessing to get them into the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = {\n",
    "    \"dog\" : \"../.assets/data/xai_images/dog.10.jpg\",\n",
    "    \"wolf 1\":  \"../.assets/data/xai_images/wolves-at-play.jpg\",\n",
    "    \"dog guitar\": \"../.assets/data/xai_images/dog-guitar.jpg\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    \"\"\"Preprocess the \"\"\"\n",
    "    img = load_img(\n",
    "        img_path, \n",
    "        target_size=(299, 299)\n",
    "    )\n",
    "    img_array = img_to_array(img)\n",
    "    #img_array = numpy.expand_dims(img_array, axis=0)\n",
    "    img_array = inception_v3.preprocess_input(img_array)\n",
    "    img_array = img_array / 2 + 0.5  # brighten\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dict(\n",
    "    (key, preprocess_image(img_path))\n",
    "              for key, img_path in image_paths.items()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[\"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[\"wolf 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[\"dog guitar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call the model on these images and obtain a classification including how confident the network is in its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inception_model.predict(\n",
    "    numpy.array(list(images.values()))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_predictions = imagenet_utils.decode_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[\"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(\n",
    "    decoded_predictions[0], \n",
    "    columns=[\"class\", \"label\", \"confidence\"]\n",
    ").set_index(\"label\").plot(kind=\"bar\", ylim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[\"wolf 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(\n",
    "    decoded_predictions[1], \n",
    "    columns=[\"class\", \"label\", \"confidence\"]\n",
    ").set_index(\"label\").plot(kind=\"bar\", ylim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[\"dog guitar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(\n",
    "    decoded_predictions[2], \n",
    "    columns=[\"class\", \"label\", \"confidence\"]\n",
    ").set_index(\"label\").plot(kind=\"bar\", ylim=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining Image Classification with LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**LIME**](https://github.com/marcotcr/lime) is an algorithm library that aims to explain the answers of any classifier, including but not limited to neural networks. LIME includes tools specific for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_image import LimeImageExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining an instance is rather compute-intensive since it in turn involves estimating a machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(\n",
    "    images[\"dog\"].astype(\"double\"),\n",
    "    inception_model.predict, \n",
    "    top_labels=5, \n",
    "    hide_color=0, \n",
    "    num_samples=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_image, mask = explanation.get_image_and_mask(\n",
    "    explanation.top_labels[0], \n",
    "    positive_only=True, \n",
    "    num_features=5, \n",
    "    hide_rest=True\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(mark_boundaries(explained_image, mask))\n",
    "plt.figure()\n",
    "plt.imshow(images[\"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the ears!\n",
    "\n",
    "> The skull should be broad, with a long muzzle and **long, hanging ears**.\n",
    "\n",
    "-- [Wikipedia: Treeing Walker Coonhound](https://en.m.wikipedia.org/wiki/Treeing_Walker_Coonhound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(\n",
    "    images[\"wolf 1\"].astype(\"double\"), \n",
    "    inception_model.predict, \n",
    "    top_labels=5, \n",
    "    hide_color=0, \n",
    "    num_samples=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_image, mask = explanation.get_image_and_mask(\n",
    "    explanation.top_labels[0], \n",
    "    positive_only=True, \n",
    "    num_features=5, \n",
    "    hide_rest=True\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(mark_boundaries(explained_image, mask))\n",
    "plt.figure()\n",
    "plt.imshow(images[\"wolf 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the last photo, there were multiple objects detected. We can use the explainer to segment the image into the parts that provide support for each of the classes. Let's look at the classes \"chihuahua\" and \"acoustic guitar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(\n",
    "    images[\"dog guitar\"].astype(\"double\"), \n",
    "    inception_model.predict, \n",
    "    top_labels=5, \n",
    "    hide_color=0, \n",
    "    num_samples=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_image, mask = explanation.get_image_and_mask(\n",
    "    explanation.top_labels[0], \n",
    "    positive_only=True, \n",
    "    num_features=5, \n",
    "    hide_rest=True\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(mark_boundaries(explained_image, mask))\n",
    "plt.figure()\n",
    "plt.imshow(images[\"dog guitar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_image, mask = explanation.get_image_and_mask(\n",
    "    explanation.top_labels[4], \n",
    "    positive_only=True, \n",
    "    num_features=5, \n",
    "    hide_rest=True\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(mark_boundaries(explained_image, mask))\n",
    "plt.figure()\n",
    "plt.imshow(images[\"dog guitar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Local Interpretable Model-Agnostic Explanations (LIME): An Introduction](https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime)\n",
    "- [Ribeiro et al.: _‚ÄúWhy Should I Trust You?‚Äù\n",
    "Explaining the Predictions of Any Classifier_](https://arxiv.org/pdf/1602.04938.pdf)\n",
    "- [Lapuschkin et al. : _Unmasking Clever Hans predictors and assessing\n",
    "what machines really learn_](https://www.nature.com/articles/s41467-019-08987-4.pdf)\n",
    "- [Vincent Warmerdam: How to Constrain Artificial Stupidity | PyData London 2019](https://www.youtube.com/watch?v=Z8MEFI7ZJlA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright ¬© 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
