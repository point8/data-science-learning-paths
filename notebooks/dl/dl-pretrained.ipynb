{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about not reinventing the wheel. Training a deep learning model can be expensive - neural networks are hungry for data, computing resources, and engineering time. Fortunately others have invested into building proven models and are providing them for free. In the following we will go through some examples of pretrained models and learn how to apply them for _inference_ without retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Network for Image Classification\n",
    "\n",
    "[Inception V3](https://keras.io/applications/#inceptionv3) is a deep convolutional neural network architecture for image classification. A model trained on 1000 classes from the [ImageNet](ImageNet) benchmark data set is provided with `keras`.\n",
    "\n",
    "The inception archictecure has been designed to solve the following issues:\n",
    "\n",
    "- The relevant object in the image can have a large variety of positions and sizes. This makes choosing the right kernel size for the convolution operation difficult. \n",
    "- Very deep networks are prone to overfitting, which produces models that do not generalize well, and the vanishing gradient problem, which makes training difficult.\n",
    "- Naively stacking large convolution operations is computationally expensive.\n",
    "\n",
    "The solution proposed with this architecture: Make the network not just deep but wide - with convolutional filters of different sizes operating on the image at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `keras` library comes with a set of pretrained models, including Inception V3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = inception_v3.InceptionV3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network expects input images to be of a fixed size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_dim = (299, 299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model should be able to classify a large number of everyday objects in images. Let's try a classic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://i.ytimg.com/vi/UwtTSqTbWzg/maxresdefault.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following library calls load the data from the URL into an image object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(img_url)\n",
    "img = PIL.Image.open(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now resize it to the required input size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize(inception_dim)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use `keras` preprocessing tools to convert the image object into a numpy array, having 3 channels for RGB..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a = keras.preprocessing.image.img_to_array(img)\n",
    "img_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(img_a.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and preprocess the pixel values for the inception model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a = inception_v3.preprocess_input(img_a)\n",
    "img_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(img_a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the image is ready to be fed to the model for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inception_model.predict(\n",
    "    numpy.array([img_a])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction comes in the form of a vector with a value for each of the 1000 labels in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we get text labels for the highest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decoded = keras.applications.imagenet_utils.decode_predictions(predictions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(\n",
    "    predictions_decoded,\n",
    "    columns=[\"category\", \"label\", \"value\"]\n",
    ").set_index(\"label\").plot(kind=\"bar\", ylim=(0,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you wonder:\n",
    "    \n",
    "> A tabby is any domestic cat (Felis catus) with an 'M' on its forehead, stripes by its eyes and across its cheeks, along its back, and around its legs and tail, and, differing by tabby type, characteristic striped, dotted, lined, flecked, banded or swirled patterns on the body—neck, shoulders, sides, flanks, chest and tummy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Web Inception\n",
    "\n",
    "**Wrap the code above in a method that takes the URL of an image from the web and outputs the classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = inception_v3.InceptionV3()\n",
    "    \n",
    "    def classify(self, img_url):\n",
    "        response = requests.get(img_url)\n",
    "        img = PIL.Image.open(io.BytesIO(response.content))\n",
    "        img = img.resize(inception_dim)\n",
    "        img_a = keras.preprocessing.image.img_to_array(img)\n",
    "        img_a = inception_v3.preprocess_input(img_a)\n",
    "        predictions = self.model.predict(\n",
    "            numpy.array([img_a])\n",
    "        )\n",
    "        predictions_decoded = keras.applications.imagenet_utils.decode_predictions(predictions)[0]\n",
    "        \n",
    "        # result\n",
    "        plt.imshow(img)\n",
    "        pandas.DataFrame(\n",
    "            predictions_decoded,\n",
    "            columns=[\"category\", \"label\", \"value\"]\n",
    "        ).set_index(\"label\").plot(kind=\"bar\", ylim=(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier = ImageClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier.classify(\"http://s3.amazonaws.com/assets.prod.vetstreet.com/c7/c56260a33911e087a80050568d634f/file/Egyptian-Mau-1-645mk062311.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier.classify(\"https://i2.cdn.turner.com/money/dam/assets/131011035837-panda-bamboo-1024x576.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier.classify(\"http://1.bp.blogspot.com/-d7UAmQylLK0/UXGzYtbC9EI/AAAAAAAAADQ/34uJPpP_eCo/s1600/7.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier.classify(\"https://i.pinimg.com/736x/18/f7/90/18f790b9a2e45f9d7e37174df7714249.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Development of the Inception Network](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2022 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
