{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Deep Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_science_learning_paths\n",
    "data_science_learning_paths.setup_plot_style(dark=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features make machine learning possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the **Iris** dataset? The measurements of the flower's petal and sepal dimensions are a good example of features that allow separation of observations into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graphics/iris-data.png)\n",
    "\n",
    "_Image credits: Principal Component Analysis by Sebastian Raschka_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = data_science_learning_paths.datasets.read_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(\n",
    "    iris_data,\n",
    "    vars=[\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"],\n",
    "    hue=\"species\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "\n",
    "> Coming up with features is difficult, time-consuming, requires expert knowledge. \"Applied machine learning\" is basically feature engineering.\n",
    "\n",
    "— Andrew Ng, ML researcher, [Machine Learning and AI via Brain simulations](https://forum.stanford.edu/events/2011/2011slides/plenary/2011plenaryNg.pdf)\n",
    "\n",
    "Good features are not always so easily accessible - they may hide in the messy raw data. **Feature engineering is the process of mining the data for good features.** It requires an understanding the data to create features that make machine learning algorithms work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Feature Engineering for Titanic Survival Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../.assets/data/titanic/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pandas.read_csv(data_path)\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../.assets/data/titanic/titanic-documentation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Idea: Cabins and Decks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of using some more domain knowledge to come up with a feature: We notice that we have a cabin number for some of the passengers on the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data[\"Cabin\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice a pattern? The cabin number starts with a letter. What could that mean? Let's have a look at the blueprints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Titanic_cutaway_diagram.png/515px-Titanic_cutaway_diagram.png) \n",
    "*cutaway diagram of the RNS Titanic - Source: Wikimedia Commons*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the letters refer to the ship's decks, from top to bottom. This gives us a promising hypothesis: Perhaps your chances of survival in the disaster depend on the placement of your cabin in the ship. We should test this hypothesis by deriving the deck as a new feature from the cabin number and providing it to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Cabins and Decks\n",
    "\n",
    "Derive the deck as a feature from the cabin number!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional Input Data: Where are the Features?\n",
    "\n",
    "Machine learning on tabular data is the most common use case in industry data science projects. But what about machine learning on other types of data - time series, images, audio, video? They have one thing in common: Each item is a very high-dimensional data point. \n",
    "\n",
    "Imagine trying to classify objects in a photo on the basis of the raw measurements - the RGB values of each pixel. Surely we need some clever **featurization** before we can think about tackling this problem with ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.codeproject.com/KB/cpp/1196024/classification_cat_dog.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example: Handwriting Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [MNIST](https://en.m.wikipedia.org/wiki/MNIST_database) dataset is a famous benchmark for handwriting recognition performance. The task is to recognize a handwritten digit from a small grayscale image, i.e. classification with 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(X_train[i], cmap=\"binary\")\n",
    "    plt.title(y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A (not yet deep) Network for Handwriting Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preprocessing step before training, the grayscale pixel data is scaled to the interval $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the complete workflow for neural network construction, training and classifying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = keras.models.Sequential([\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation=\"relu\"),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Dense(n_classes, activation=\"softmax\")\n",
    "])\n",
    "net.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "net.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    ")\n",
    "y_pred = numpy.argmax(net.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer a graphical summary - this one was made with the [Netron](https://github.com/lutzroeder/netron) application:\n",
    "\n",
    "![](graphics/MNIST_classifier.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(X_test[i], cmap=\"binary\")\n",
    "    plt.title(f\"pred: {y_pred[i]} actual: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning = Automated Feature Engineering\n",
    "\n",
    "A neural network can **learn to extract relevant features from complex inputs**. _Adding more layers_ can enable it to perform this task better - this is _putting the \"deep\" in \"deep learning\"_.  Each layer in the front part of the network acts as a _feature extractor_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graphics/convnet_architecture.jpg)\n",
    "\n",
    "_[Source](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graphics/cnn_feature_viz.jpg)\n",
    "\n",
    "[_Source_](https://www.researchgate.net/publication/319622441_DeepFeat_A_Bottom_Up_and_Top_Down_Saliency_Model_Based_on_Deep_Features_of_Convolutional_Neural_Nets/figures?lo=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
