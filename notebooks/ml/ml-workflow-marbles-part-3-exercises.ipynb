{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise and Feature Engineering II\n",
    "\n",
    "In the first two parts we learned a lot about the general ML-workflow. We could achieve quite reasonable results for our classification task. We already performed some feature engineering and applied a transformation to an alternative representations of the RGB color model.\n",
    "\n",
    "As mentioned before, deriving a meaningful and valid ML-model has to be an iterative process. Directly try to improve the ML-model by hyperparameter tuning is often not the first choice. So letâ€™s go back to the feature engineering part.\n",
    "\n",
    "Right now we use single color measurements of a marble to classify it. An easy way to improve the performance is to combine several measurements for each marble. In our example we will implement it by creating a tuple out of single measurements. Thereby, we will `stack` single samples to a single event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, clear_output, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import, Preparation, Feature Engineering I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lines(lines):\n",
    "    \"\"\" Parse strings of marble data\"\"\"\n",
    "    lines = lines[2:-2]\n",
    "    rows = [d.split(', ') for d in lines.split('), (')]\n",
    "    data = [[int(v.replace(')][(', '')) for v in r] for r in rows]\n",
    "    return pd.DataFrame(data)[[0, 1, 2]]\n",
    "\n",
    "files = [\n",
    "    'blue-white-glass.data',\n",
    "    'cyan-glass.data',\n",
    "    'glass-blue.data',\n",
    "    'glass-green.data',\n",
    "    'glass-red.data',\n",
    "    'glass-yellow.data',\n",
    "    'planet-black-blue.data',\n",
    "    'planet-green.data',\n",
    "    'planet-ocean.data',\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for i, fname in enumerate(files):\n",
    "    print(f'Load data {i}: {fname}')\n",
    "\n",
    "    with zipfile.ZipFile(f'../.assets/data/marbles/{fname}.zip', 'r') as zipf:\n",
    "        with zipf.open(f'{fname}', 'r') as infile:\n",
    "            content = infile.readlines()[0].decode()\n",
    "            dfs.append(parse_lines(content).assign(color=f'{fname}'.replace('.data', '')))\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.columns=['R', 'G', 'B', 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xy_values(df):\n",
    "    df['X'] = 0.5 * np.sqrt(3) * df['G'] - 0.5 * np.sqrt(3) * df['B']\n",
    "    df['Y'] = df['R'] - (1 / 3 * df['G']) - (1 / 3 * df['B'])\n",
    "    \n",
    "def generate_intensity_values(df):\n",
    "    df['I'] = np.square(df['X']) + np.square(df['Y'])\n",
    "\n",
    "def generate_angles(df):\n",
    "    df['Phi'] = np.arctan2(df['Y'], df['X'])\n",
    "\n",
    "# Feature Engineering I - we can add later   \n",
    "#generate_xy_values(df)\n",
    "#generate_intensity_values(df)\n",
    "#generate_angles(df)\n",
    "\n",
    "# Add target ID\n",
    "ids = {'blue-white-glass': 0,\n",
    "      'cyan-glass': 1,\n",
    "      'glass-blue': 2,\n",
    "      'glass-green': 3,\n",
    "      'glass-red': 4,\n",
    "      'glass-yellow': 5,\n",
    "      'planet-black-blue': 6,\n",
    "      'planet-green': 7,\n",
    "      'planet-ocean': 8,}\n",
    "\n",
    "df['cat'] = df['color'].map(ids)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples per event\n",
    "VALUES_PER_EVENT = 15\n",
    "\n",
    "# List of data sets\n",
    "dfs = []\n",
    "\n",
    "for i in range(9):\n",
    "    \n",
    "    # Get all samples of one type\n",
    "    df_i = df[df['cat']==i]\n",
    "    \n",
    "    # Delete color and cat\n",
    "    df_i = df_i.drop(labels=['cat'], axis=1)\n",
    "    color = df_i.color[0]\n",
    "    df_i = df_i.drop(labels=['color'], axis=1)\n",
    "    \n",
    "    # Create Package\n",
    "    df_i['meas'] = (df_i.index.values / VALUES_PER_EVENT).astype('Int64')\n",
    "    df_i['index'] = df_i.index % VALUES_PER_EVENT\n",
    " \n",
    "    # Create mean\n",
    "    rm = df_i.groupby('meas')['R'].mean()\n",
    "    gm = df_i.groupby('meas')['G'].mean()\n",
    "    bm = df_i.groupby('meas')['B'].mean()\n",
    "    \n",
    "    # Create standard deviations\n",
    "    rv = df_i.groupby('meas')['R'].std()\n",
    "    gv = df_i.groupby('meas')['G'].std()\n",
    "    bv = df_i.groupby('meas')['B'].std()\n",
    "    \n",
    "    # Unstack\n",
    "    df_i = df_i.set_index(['meas','index']).unstack(level=1)\n",
    "    df_i.columns = [ f'{x}_{y}' for x in df_i.columns.levels[0] for y in df_i.columns.levels[1]]\n",
    "    \n",
    "    # Add mean and std \n",
    "    df_i['R_M'] = rm\n",
    "    df_i['G_M'] = gm\n",
    "    df_i['B_M'] = bm\n",
    "    \n",
    "    df_i['R_V'] = rv\n",
    "    df_i['G_V'] = gv\n",
    "    df_i['B_V'] = bv\n",
    "    \n",
    "    # Add target\n",
    "    df_i['cat'] = i\n",
    "    df_i['color'] = color\n",
    "    \n",
    "    # Add to list of data sets\n",
    "    dfs.append(df_i)\n",
    "\n",
    "# Combine to one dataframe    \n",
    "df = pd.concat(dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix data set\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with ML\n",
    "- Your task is to built up the ML workflow. Start with defining the training features, set up training and test data set, import relevant modules...\n",
    "\n",
    "- You may want to give it another try with unsupervised learning (e.g. Gaussian Mixture)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It's your turn!\n",
    "\n",
    "training_features = []\n",
    "target = ['']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#......\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = [c  for c in df.columns if (('R' in c) or ('G' in c) or ('B' in c))]\n",
    "\n",
    "target = ['cat']\n",
    "\n",
    "X = df[training_features + target].dropna()\n",
    "y = X[target]\n",
    "X.drop(target, axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, max_depth=10) # Start\n",
    "#model = RandomForestClassifier(n_estimators=100, max_depth=None) # TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit des Modells\n",
    "model.fit(X_train, y_train.values[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "truth = y_test \n",
    "cm = confusion_matrix(truth,y_pred_test)\n",
    "\n",
    "pd.DataFrame(data=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='viridis',vmin=0, vmax=df.shape[0]/9*0.2)\n",
    "plt.colorbar()\n",
    "for i, j in itertools.product(range(9), range(9)):\n",
    "        plt.text(j, i, f'{cm[i, j]:.0f}', horizontalalignment=\"center\",color=\"white\" if not i==j else \"black\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class');        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat = [0,1,2,3,4,5,6,7,8]\n",
    "cat = [0, 4, 8]\n",
    "\n",
    "y_proba_test = model.predict_proba(X_test)\n",
    "\n",
    "for i in cat:\n",
    "    y_proba_test_i = y_proba_test[:,i]\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    for j in range(9):\n",
    "        plt.hist(y_proba_test_i[y_test['cat'] == j], \n",
    "                 bins=np.linspace(0,1,100), \n",
    "                 alpha=0.5, \n",
    "                 density=False, \n",
    "                 label=f'Type {j}')        \n",
    "    \n",
    "    plt.title(f'Hypothesis: Marble belongs to type {i}')\n",
    "    plt.xlabel('Probability')   \n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat = [0,1,2,3,4,5,6,7,8]\n",
    "cat = [0, 4, 8]\n",
    "\n",
    "y_proba_test = model.predict_proba(X_test)\n",
    "y_proba_train = model.predict_proba(X_train)\n",
    "   \n",
    "for i in cat:\n",
    "    y_proba_test_i = y_proba_test[:,i]\n",
    "    y_proba_train_i = y_proba_train[:,i]\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(*roc_curve(y_test == i, y_proba_test_i)[:2], label='test')\n",
    "    plt.plot(*roc_curve(y_train == i, y_proba_train_i)[:2], label='train')\n",
    "    plt.plot([0, 1],[0, 1], color='black', linestyle=':')\n",
    "    plt.title(f'ROC curve type {i}')\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate') \n",
    "    plt.legend(loc='best')\n",
    "    plt.show();   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "plt.barh(range(len(X.columns)), model.feature_importances_)\n",
    "plt.yticks(range(len(X.columns)), X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(9):\n",
    "    y_proba_test_i = y_proba_test[:,i]\n",
    "    data.append(roc_auc_score(y_test.values == i, y_proba_test_i))\n",
    "    \n",
    "# Displaying\n",
    "pd.DataFrame(np.array(data), columns=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean Accuracy: {model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning with Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [0,1,2,3,4,5,6,7,8]\n",
    "\n",
    "X = df[df['cat'].isin(cat)][['R_M','G_M','B_M','R_V','B_V','G_V','cat']]\n",
    "\n",
    "# Reduced data set size\n",
    "X = X.sample(10000)\n",
    "\n",
    "# Define target for visualiztion\n",
    "target = X['cat']\n",
    "X=X.drop(['cat'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], color=cmap(target), s=5, label ='Truth')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "model = GaussianMixture(n_components=9, init_params='kmeans')\n",
    "model.fit(X)\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=20, color = cmap(predictions), alpha=0.5, label='Predictions Gaussian Mixture')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright Â© 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
