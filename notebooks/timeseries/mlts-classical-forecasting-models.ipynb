{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Time Series Forecasting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we learn about so-called _classical_ time series models that statisticians have developed to model and forecast time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this Machine Learning or Statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a trick question: In many ways, machine learning is just conveniently automated statistical modelling. Let's adopt the following precise definition of machine learning: **Machine learning is when a computer program improves its performance with experience**, i.e. by seeing data points/examples and using them to build a good model for the task at hand. This definition is rather broad, and not only encompasses fancy methods like neural networks, but also quite simple ones, like iteratively fitting a regression line to a set of points in 2D.\n",
    "\n",
    "In this chapter we are going to introduce some **classical time series models** that can be used for generating a time series, and therefore, for **forecasting**. In a broad sense, this is also machine learning: To achieve good forecasting performance, such a classical model also need to be fitted to the data of a time series to estimate its parameters. Why then do data scientist often make a distinction between _classical time series modelling_, and _machine learning on time series_? There are historical reasons, with ML being considered more modern. But we also note some technical differences between the approaches: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| classical statistical approach                                                      | machine learning approach                                                |\n",
    "|--------------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| careful statistical modeling: theory, preconditions/assumptions, explainability... | whatever works: focus on performance                                               |\n",
    "| focus on univariate models                                                                   | more open to incorporating multivariate timeseries or external variables |\n",
    "| often linear models                                                                 | more algorithmic variety, nonlinear models   |\n",
    "| stochastic process perspective | anything goes...                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common to all classical time series models is the view that **time series values are the result of a stochastic process**: A **stochastic process** is any system that changes over time, with randomness involved, and outputs a time series of values. The goal is to estimate a good model of the stochastic process that has generated the time series data we see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_science_learning_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_science_learning_paths.setup_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset matplotlib_converters to standards \n",
    "pandas.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Climate Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset of the average monthly temperature in the USA over more than one century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_temp = data_science_learning_paths.datasets.read_usa_temperature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_temp[\"Value\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `statsmodels` to fit a model of the **ARMA** type to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sm.tsa.ARMA(\n",
    "    usa_temp[\"Value\"],\n",
    "    order=(12,1)\n",
    ")\n",
    "model = estimator.fit(maxiter=1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `summary` method outputs a large amount of diagnostic information about the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot_predict` method shows actuals and one-step-ahead forecasts by the model. What we see is a first indication that the model has the ability to predict the correct values. However, this is not yet a proper multi-step forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_predict(start=0, end=10 * 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a true forecast, we fit to a prefix of the time series, call the `forecast` method with the length of the remainder as horizon and compare actuals to predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sm.tsa.ARMA(\n",
    "    usa_temp[\"Value\"][:\"2000\"],\n",
    "    order=(14,1)\n",
    ")\n",
    "model = estimator.fit(maxiter=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = usa_temp[\"Value\"][\"2000\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecast includes both an error estimation and confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_f, err, conf_int = model.forecast(steps=229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(\n",
    "    {\n",
    "        \"forecast\": y_f,\n",
    "        \"conf_low\": conf_int[:, 0],\n",
    "        \"conf_high\": conf_int[:, 1],\n",
    "        \"actual\": y_test\n",
    "    }\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity\n",
    "\n",
    "A stochastic process is **stationary** if its **probability distribution does not change overtime**. Consequently, parameters such as mean and variance also do not change over time.\n",
    "\n",
    "_An ARMA model has stationarity as a precondition._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proving stationarity is not trivial. However, we can use statistical testing to do a quick check on whether a time series should be assumed to be stationary. \n",
    "\n",
    "One such test is the **Augmented Dickey-Fuller Test**. It can be understood as a **hypothesis test** about whether the time series is defined by a time-dependent structure, such as a trend:\n",
    "\n",
    "- H0 (null-hypothesis): The time series is non-stationary.\n",
    "- H1 (alternative hypothesis): The time series is stationary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_adfuller_result(result):\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_adfuller_result(\n",
    "    adfuller(usa_temp[\"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the output:\n",
    "1. See the value of the ADF statistic and check whether it is **lower than the critical value at the desired significance level**. (The **significance level** can be understood as the probability that we see this result by chance).\n",
    "2. If it is, we can **reject the null-hypothesis**, i.e. we can assume the time series to be stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_adfuller_result(\n",
    "    adfuller(usa_temp[\"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_adfuller_result(\n",
    "    adfuller(usa_temp[\"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Hyper)Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**Autoregressive Moving Average (ARMA) model**](https://en.m.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model) describes a _stationary_ stochastic process in terms of two polynomials:\n",
    "\n",
    "**Moving Averages - $MA(q)$**\n",
    "\n",
    "$$MA(q): y_t = \\epsilon_t + a_1 \\epsilon_t + \\dots + a_q \\epsilon_{t-q} $$\n",
    "\n",
    "**Autoregressive Process - $AR(p)$**\n",
    "\n",
    "$$AR(p): y_t = \\sum_{i=1}^p a_i y_{t-i} + \\epsilon_t$$\n",
    "\n",
    "**ARMA - $ARMA(p,q)$**\n",
    "\n",
    "$$ARMA(p,q): y_t = AR(p) + MA(q) + \\epsilon_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate the hyperparameters $p$ and $q$, called the **order** of the model, two strategies present themselves:\n",
    "\n",
    "1. estimate the order of the model manually by statistical means\n",
    "2. use parameter search and raw compute power to select the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. estimating the order of the model**\n",
    "\n",
    "Plotting the **autocorrelation** and **partial autocorrelation functions** provides information on choosing $q$ and $p$ respectively. [More information here](https://people.duke.edu/~rnau/411arim3.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(\n",
    "    usa_temp[\"Value\"],\n",
    "    lags=50,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(\n",
    "    usa_temp[\"Value\"],\n",
    "    lags=50,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic process models like ARMA can also be used for generating time series data from scratch by initializing the model with the appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_process import arma_generate_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_coeff = numpy.random.uniform(-1, 1, 4)\n",
    "ar_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = arma_generate_sample(\n",
    "    ar=[1, -1, ],\n",
    "    ma=[1],\n",
    "    sigma=.2,\n",
    "    nsample=int(1e4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(\n",
    "    y,\n",
    "    lags=50,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Stationary Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **stationarize** the time series, e.g. by subtracting the trend component and adding it back to the forecasts later\n",
    "- use models that can deal with non-stationary data\n",
    "    - e.g [**ARIMA**](https://en.m.wikipedia.org/wiki/Autoregressive_integrated_moving_average), which has one additional hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**\n",
    "\n",
    "- rich theory: statistical motivation and explainability\n",
    "- error and confidence interval estimation\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- rich theory\n",
    "- manual estimation of hyperparameters (model order)\n",
    "- compute time for fitting increases strongly with model order\n",
    "- adding external variables is not straightforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Machine Learning Mastery: How to Check if Time Series Data is Stationary with Python](https://machinelearningmastery.com/time-series-data-stationary-python/)\n",
    "- [O'Reilly: Machine Learning for Time Series Data Analysis—Best Practices in Prediction and Anomaly Detection Using Python ](https://learning.oreilly.com/learning-paths/learning-path-machine/9781492025528/9781492025504-video318126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
