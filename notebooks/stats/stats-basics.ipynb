{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic basics\n",
    "\n",
    "Most tools of trade of a Data Scientist are based or directly stem from the mathematical field of statistics. Because of that we will now review the basic concepts. These concepts are the fundamentals for a deeper understanding of the following algorithms and ideas.\n",
    "\n",
    "To fresh things up we will understand the theoretical concepts using example data. The _Iris data set_ is very famous around machine learning tutorials.\n",
    "\n",
    "First some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris data set\n",
    "\n",
    "![Iris versicolor](https://upload.wikimedia.org/wikipedia/commons/d/db/Iris_versicolor_4.jpg)\n",
    "\n",
    "> The Iris flower data set or \"Fisher's Iris data set\" is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper _The use of multiple measurements in taxonomic problems_ as an example of linear discriminant analysis.\n",
    "> \n",
    "> The data set consists of 50 samples from each of three species of Iris (_Iris setosa_, _Iris virginica_ and _Iris versicolor_). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other.\n",
    "> &mdash; [\"Iris flower data set,\" Wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "Quite convenient for users, the data set is part of the Python machine learning library [**scikit-learn**](http://scikit-learn.org/stable/) (`sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris['data'])\n",
    "df.columns = iris['feature_names']\n",
    "df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is downloaded from the internet and a `pandas.DataFrame` is constructed. The DataFrame columns contain the four different features (_sepal length_, _sepal width_, _petal length_ and _petal width_) as well a `target` column encoding the true Iris species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows seem sorted, to get a better overview, we will look at a random sample of 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "\n",
    "Whenever working with a new data set, we start by getting a good overview of the data and its characteristics. This works either by looking at summary statistics or visualizing the data - usually both approaches are combined.\n",
    "\n",
    "### Descriptive statistics\n",
    "\n",
    "To get an easy access to a new data set a look at some key figures is an easy way. Pandas has everything we need on board, it's easy to calculate means, standard deviations and other basic statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_column(df, column_name):\n",
    "    # Pick a column\n",
    "    column = df[column_name]\n",
    "    \n",
    "    # Get unit from column name\n",
    "    s = column_name.split()\n",
    "    name = ' '.join(s[:2])\n",
    "    unit = s[2].strip('()')\n",
    "    \n",
    "    # Some key figures\n",
    "    count = column.count()\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    \n",
    "    # Output\n",
    "    print(\n",
    "        f'The sample (size={count}) of data in column \"{name}\" has a mean of {mean:.2f} {unit} with a standard deviation of {std:.2f} {unit}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_column(df, 'sepal length (cm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_column(df, 'petal length (cm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example includes the following statistical figures:\n",
    "\n",
    "- **Sample size** `column.count()`\n",
    "- **Arithmetic mean** `column.mean()`\n",
    "- **Standard deviation** `column.std()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Define a new function using one or more of the following statistical figures:\n",
    "\n",
    "\n",
    "- `column.sem()`\n",
    "- `column.median()`\n",
    "- `column.quantile()`\n",
    "- `column.var()`\n",
    "- `column.min()`\n",
    "- `column.max()`\n",
    "\n",
    "You can find the [documentation online](http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built in function `pandas.DataFrame.describe()` calculates and shows some of the discussed figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add-on: Separating target classes\n",
    "\n",
    "We modify the already defined function `analyse_column` to allow calculating the descriptive statistical figures for just one of the target classes (_i.e._ Iris species)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_column_kind(df, column_name, kind=None):\n",
    "    if kind is not None:\n",
    "        df = df[df['target'] == kind]\n",
    "        print(f'Species: {kind}:')\n",
    "    else:\n",
    "        print(f'For all species:')\n",
    "        \n",
    "    analyse_column(df, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_column_kind(df, 'petal length (cm)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in df['target'].unique():\n",
    "    analyse_column_kind(df, 'sepal length (cm)', kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussing the results\n",
    "\n",
    "The different species of flowers show differences in the distribution and key figures of the provided features. This allows a classification. To get an even better understanding of the data, we will now plot some histrograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "\n",
    "Let's have a look at the feature `sepal length` and plot the sample distribution for all three classes in a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'sepal length (cm)'\n",
    "\n",
    "labels = [f'Species {kind}' for kind in df['target'].unique()]\n",
    "hists = [df[df['target'] == kind][feature] for kind in df['target'].unique()]\n",
    "plt.hist(hists, alpha=0.8, bins=np.linspace(3, 9, 20))\n",
    "plt.legend(labels)\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Number of entries per bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "The parameter `bins` is already familiar. Until now we always assigned a whole-number describing the total number of bins. Now we use numpy's `np.linspace(3, 9, 13)` to create an array of 13 bin boundaries, that are uniformly distributed over the interval 3 - 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Samples and Distributions\n",
    "\n",
    "The Iris data set has a **sample size** of 150. Selecting only data for one Iris species results in a sample size of 50.\n",
    "\n",
    "Let's have a look at two different samples of randomly generated numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large sample with 20k items\n",
    "big = np.random.normal(loc=0.0, scale=10.0, size=20000)\n",
    "\n",
    "# small sample with 1000 items\n",
    "small = np.random.normal(loc=0.0, scale=10.0, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(big, bins=np.linspace(-40, 40, 100), color='dodgerblue', alpha=0.5, density=False)\n",
    "plt.hist(small, bins=np.linspace(-40, 40, 100), alpha=0.5, density=False)\n",
    "plt.xlabel('Normal distribution')\n",
    "plt.ylabel('Number of entries per bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the histograms of the large and the small sample look very different at first glance, the underlying **distribution** is exactly the same.\n",
    "\n",
    "In this case the data is normally distributed or \"it follows a normal distribution\". This distribution is very typical for most processees in nature. The mean of the distribution is the most probable value, the so called _expactation value_, while the width of the normal distribution is described by the _standard deviation_. The normal distribution is a symmetric distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=1, sharey=True)\n",
    "axes[0].hist(big, bins=np.linspace(-40, 40, 100), color='dodgerblue', alpha=0.5, density=True)\n",
    "axes[1].hist(small, bins=np.linspace(-40, 40, 100), alpha=0.5, density=True)\n",
    "axes[0].set_ylabel('Number of entries per bin (normalized)')\n",
    "axes[0].set_xlabel('large sample')\n",
    "axes[1].set_xlabel('small sample');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better compare the two samples, we normalize the histograms. This means each bin entry is divided by the sample size.\n",
    "\n",
    "Beside the **arithmetic mean**, we know another central value describing the distribution. The **median** is the \"middle\" value after sorting all values, i.e. the median splits the sample in two halfs. While the mean is usualy the more familiar measure, the median has some advantages concerning it's robustness against outliers in the data sample.\n",
    "\n",
    "**Percentiles** are the generalization of this concept:\n",
    "\n",
    "> A percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value (or score) below which 20% of the observations may be found. &mdash; [\"Percentile,\" Wikipedia](https://en.wikipedia.org/w/index.php?title=Percentile&oldid=825250895)\n",
    "\n",
    "Thus the median is the equivalent to the 50%-percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add some outliers\n",
    "outlier = [45, 50, 48, 35, 35, 35, 35, 5000]\n",
    "big_outlier = np.append(big, outlier)\n",
    "small_outlier = np.append(small, outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=1, sharey=True)\n",
    "axes[0].hist(big_outlier, bins=np.linspace(-40,40,100), color='dodgerblue', alpha=0.5, density=True)\n",
    "axes[1].hist(small_outlier, bins=np.linspace(-40,40,100), alpha=0.5, density=True)\n",
    "\n",
    "axes[0].axvline(np.mean(big_outlier), color='black', linestyle='solid', linewidth=2, label='Arithmetic mean')\n",
    "axes[1].axvline(np.mean(small_outlier), color='black', linestyle='solid', linewidth=2, label='Arithmetic mean')\n",
    "axes[0].axvline(np.median(big_outlier), color='darkgreen', linestyle='dashed', linewidth=2, label='Median')\n",
    "axes[1].axvline(np.median(small_outlier), color='darkgreen', linestyle='dashed', linewidth=2, label='Median')\n",
    "\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "axes[0].set_ylabel('Number of entries per bin (normalized)')\n",
    "axes[0].set_xlabel('large sample with outliers')\n",
    "axes[1].set_xlabel('small sample with outliers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **standard deviation** as well as the **variance** describe the width of a distribution. In broad distributions the data points show a larger spread around the central value. The variance describes the mean distance between each value and the central value.\n",
    "\n",
    "The standard deviation is calculated as the square root of the variance. In a normally distributed data sample approximately 68% of data points are within one standard deviation (also called $\\sigma$ (sigma)) around the central value and approximately 95% of data points within two standard deviations (2$\\sigma$).\n",
    "\n",
    "The **standard error of the mean** is calculated as the standard deviation divided by the square root of the sample size. It is a measure of uncertainty, indicating how accurately the mean of the sample represents the mean of the distribution. Unlike the standard deviation, the standard error of the mean shrinks with increasing sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(big, bins=np.linspace(-40, 40, 100), color='dodgerblue', alpha=0.5, density=False)\n",
    "\n",
    "plt.axvline(big.mean(), color='black', linestyle='solid', linewidth=2)\n",
    "plt.axvline((big.mean() + big.std()), color='darkgreen', linestyle='solid', linewidth=2, label='1$\\sigma$ (~68%)')\n",
    "plt.axvline((big.mean() - big.std()), color='darkgreen', linestyle='solid', linewidth=2)\n",
    "plt.axvline((big.mean() + 2 * big.std()), color='darkgreen', linestyle='dashed', linewidth=2, label='2$\\sigma$ (~95%)')\n",
    "plt.axvline((big.mean() - 2 * big.std()), color='darkgreen', linestyle='dashed', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Normal distribution')\n",
    "plt.ylabel('Number of entries per bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Separation of two variables\n",
    "\n",
    "The Iris data set includes four different feature variables: the length and width of the flowers petals and sepals. We will now combine two of the features into one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sepal length (cm)'\n",
    "# 'sepal width (cm)'\n",
    "# 'petal length (cm)'\n",
    "# 'petal width (cm)'\n",
    "feature_A = 'sepal width (cm)'\n",
    "feature_B = 'sepal length (cm)'\n",
    "plt.scatter(\n",
    "    df[feature_A],\n",
    "    df[feature_B],\n",
    "    c=df['target'],# 'third axis' = color\n",
    "    cmap='Set1',   # colormap\n",
    "    s=100,          # dot size\n",
    ");\n",
    "plt.xlabel(feature_A)\n",
    "plt.ylabel(feature_B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this overview plot we combine all length-width combinations. In total we could show six different plots if we would plot length-length and width-width combinations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2)\n",
    "\n",
    "# Create four sub-plots\n",
    "axes[0][0].scatter(df['sepal width (cm)'], df['sepal length (cm)'], c=df['target'], cmap=plt.cm.Set1, s=50)\n",
    "axes[0][1].scatter(df['petal width (cm)'], df['sepal length (cm)'], c=df['target'], cmap=plt.cm.Set1, s=50)\n",
    "axes[1][0].scatter(df['sepal width (cm)'], df['petal length (cm)'], c=df['target'], cmap=plt.cm.Set1, s=50)\n",
    "axes[1][1].scatter(df['petal width (cm)'], df['petal length (cm)'], c=df['target'], cmap=plt.cm.Set1, s=50)\n",
    "\n",
    "# Axis labels\n",
    "axes[0][0].set_ylabel('sepal length (cm)')\n",
    "axes[1][0].set_ylabel('petal length (cm)')\n",
    "axes[1][0].set_xlabel('sepal width (cm)')\n",
    "axes[1][1].set_xlabel('petal width (cm)')\n",
    "\n",
    "# Axis ranges\n",
    "axes[0][0].set_ylim(3.5, 8.5)\n",
    "axes[0][1].set_ylim(3.5, 8.5)\n",
    "axes[1][0].set_ylim(0, 8)\n",
    "axes[1][1].set_ylim(0, 8)\n",
    "\n",
    "# Remove axis labels for inner axes\n",
    "plt.setp(axes[0][0].get_xticklabels(), visible=False)\n",
    "plt.setp(axes[0][1].get_yticklabels(), visible=False)\n",
    "plt.setp(axes[0][1].get_xticklabels(), visible=False)\n",
    "plt.setp(axes[1][1].get_yticklabels(), visible=False)\n",
    "\n",
    "fig.subplots_adjust(hspace=0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the resulting plots\n",
    "\n",
    "In this visualization we represent the three species using three different colors. The ability to distinguish between the flower species varies depending on the two features we combine in the scatter plot. \n",
    "\n",
    "As a general rule in machine learning we try to find features that provides us with a good separation of at least two target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The science behind correlations\n",
    "\n",
    "For a better understanding of the interaction of two features, we can explore their **correlation**. Usually understood as a measure for the linear relationship of two variables, correlation is an important measure given that it is applied correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['target'] == 2]['sepal width (cm)']\n",
    "y = df[df['target'] == 2]['petal width (cm)']\n",
    "\n",
    "# 2x2 grid\n",
    "plt.figure(figsize=(10, 10))\n",
    "gs1 = gridspec.GridSpec(2, 2, height_ratios=[1, 3], width_ratios=[3, 1])\n",
    "gs1.update(wspace=0.0, hspace=0.0)\n",
    "\n",
    "# scatter plot\n",
    "ax2 = plt.subplot(gs1[2])\n",
    "ax2.scatter(x, y ,s=50, color='dodgerblue')\n",
    "ax2.set_xlabel('sepal width (cm)')\n",
    "ax2.set_ylabel('petal width (cm)')\n",
    "\n",
    "# upper histogramm\n",
    "ax0 = plt.subplot(gs1[0], sharex=ax2)\n",
    "ax0.hist(x, color='dodgerblue')\n",
    "plt.setp( ax0.get_xticklabels(), visible=False)\n",
    "\n",
    "# right histogramm\n",
    "ax3 = plt.subplot(gs1[3], sharey=ax2)\n",
    "ax3.hist(y, orientation='horizontal', color='dodgerblue')\n",
    "plt.setp( ax3.get_yticklabels(), visible=False)\n",
    "\n",
    "# Calculaitng the parameters of the correlation matrices\n",
    "eigenvectors = np.linalg.eig(np.cov(x, y))\n",
    "print('Covariance matrix\\n', np.cov(x, y))\n",
    "ev = eigenvectors[0]\n",
    "ex = eigenvectors[1][0]\n",
    "ey = eigenvectors[1][1]\n",
    "\n",
    "angle = np.arctan(ey[0] / ey[1]) / np.pi * 180\n",
    "\n",
    "# Draw ellipses\n",
    "ax2.add_artist(\n",
    "    mpl.patches.Ellipse(xy=(x.mean(), y.mean()),\n",
    "                        width=2 * np.sqrt(ev[0]),\n",
    "                        height=2 * np.sqrt(ev[1]),\n",
    "                        angle=angle,\n",
    "                        color='dodgerblue',\n",
    "                        alpha=0.30))\n",
    "ax2.add_artist(\n",
    "    mpl.patches.Ellipse(xy=(x.mean(), y.mean()),\n",
    "                        width=2 * 2 * np.sqrt(ev[0]),\n",
    "                        height=2 * 2 * np.sqrt(ev[1]),\n",
    "                        angle=angle,\n",
    "                        color='dodgerblue',\n",
    "                        alpha=0.30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the resulting plot\n",
    "\n",
    "The main part of the visualization is a scatter plot of the two features _petal width_ and _sepal width_. The histograms at the top and right side of the main plot show the one dimensional distribution for each feature. The ellipses in light blue show the 68% (and 95%) countour (one and two $\\sigma$) of the two dimensional distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient (Pearson correlation)\n",
    "\n",
    "The linear correlation between two variables can be quantified using the correlation coefficient (often depicted as $\\rho$ (rho)). A coefficient of 0 means _no linear correlation_ while a coefficient of +1 or -1 stands for maximal correlation or anti-correlation.\n",
    "\n",
    "Here we use the function `pearsonr` included in the [**scipy**](https://www.scipy.org) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "rho = pearsonr(x, y)[0]\n",
    "print(f'The linear correlation of the two variables in the data sample is {rho:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning\n",
    "\n",
    "Use the correlation coefficent with caution! If there is a non-linear relation between the variables the value of the coefficient is misleading. Plotting the data helps in this case to spot possible traps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright Â© 2018-2026 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
