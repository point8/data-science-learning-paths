{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling with Pandas\n",
    "\n",
    "\n",
    "While the [**numpy**](http://www.numpy.org/) library provides strong numerical operations for multidimensional arrays, [**pandas**](https://pandas.pydata.org/) focuses on data analysis. It is a collection of powerful tools for importing, rearranging, analyzing, and exporting tabular data sets.\n",
    "\n",
    "[**pandas documentation**](http://pandas.pydata.org/pandas-docs/stable/): _\"pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis/manipulation tool available in any language. It is already well on its way toward this goal.“_\n",
    "\n",
    "Pandas uses the core functionality of numpy to handle its prominent data structure called the [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) (an concept which originated in [**R**](https://www.r-project.org)). Pandas provides a wide range of functions for data analysis like importing and exporting, viewing, selection, indexing, handling missing data, statistical analyses, merging, grouping, reshaping, handling time series of data and much more. It also enables plotting via the [**matplotlib**](https://matplotlib.org/) library on a high-level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Pandas\n",
    "\n",
    "It is common to use the abbreviation `pd` for pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at a dataset: Wine Quality\n",
    "\n",
    "To get used to the basic functionality of the `pandas` library we are now going to work with an example data set. The data set is of roughly 1600 different red wine and around 5000 white wine samples ([Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/Wine%2BQuality)). The different columns are chemical and physical attributes. In addition a quality score is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINE_COLOR = \"red\"  # or white\n",
    "df = pd.read_csv(f\"../.assets/data/winequality/{WINE_COLOR}.csv.zip\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set size: ~5000 (~1600) different white (red) wines with 12 different attributes\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a default integer index\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last 5 rows\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample of 4 rows\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column\n",
    "df[\"pH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of three columns\n",
    "df[[\"pH\", \"citric acid\", \"quality\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique values in a column\n",
    "df[\"quality\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data set by column `pH`\n",
    "df.sort_values(by=\"pH\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values\n",
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get size (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get more info on dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures: pandas.Series and pandas.DataFrame\n",
    "\n",
    "The [**pandas.Series**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. `Series` acts very similarly to a `ndarray`, and is a valid argument to most `numpy` functions. A series conists of the `index` and respective `values`. However, operations such as slicing will also slice the index.\n",
    "\n",
    "The [**pandas.DataFrame**](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) is the central data structure of pandas. `DataFrame` is a 2-dimensional labeled data structure with columns of potentially different types. Data coming from e.g. Excel or other SQL(-like) structures can be easily converted to a pandas DataFrame. \n",
    "\n",
    "<img src=\"graphics/pandas_dataframe_series.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and export data to and from pandas.DataFrame\n",
    "\n",
    "Many methods for data IO are included in `pandas`, and standard file type are supported. A full list of them can be found [here](https://pandas.pydata.org/pandas-docs/stable/io.html). Some supported file types are:\n",
    "* [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) (`read_csv()`, `to_csv()`)\n",
    "* [JSON](http://www.json.org/) (`read_json()`, `to_json()`)\n",
    "* [MS Excel](https://en.wikipedia.org/wiki/Microsoft_Excel) (`read_excel()`, `to_excel()`)\n",
    "* [SQL](https://en.wikipedia.org/wiki/SQL) (`read_sql()`, `to_sql()`)\n",
    "* [Python Pickle Format](https://docs.python.org/3/library/pickle.html) (`read_pickle()`, `to_pickle()`)\n",
    "* ...\n",
    "\n",
    "The example shows the basic principle of importing and exporting data from/to files. In the case of text-based file types (e.g. csv) one important parameter to set is the separator (`sep`). This can probably interfere with the decimal separator and should be checked. In the case of an Excel file sheet name has to be set with `sheet_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import with setting the first column (index_col=0) as index or the sheet_name, respectively\n",
    "df_csv_import = pd.read_csv(\"data.csv\", sep=\",\", index_col=0)\n",
    "df_excel_import = pd.read_excel(\"data.xls\", sheet_name=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the built pandas.DataFrame to csv and excel files\n",
    "df_csv_import.to_csv(\"data_new.csv\", sep=\",\")\n",
    "df_csv_import.to_excel(\"data_new.xlsx\", sheet_name=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More basic handling of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to the bigger wine dataset. There are several ways to select single rows or single columns by the index or its column name, respectively. Selection rows via use of `[]` or `loc[]` are the easiest ways. Let's get back to our wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINE_COLOR = \"red\"  # or white\n",
    "df = pd.read_csv(f\"../.assets/data/winequality/{WINE_COLOR}.csv.zip\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column by value\n",
    "df[\"color\"] = WINE_COLOR\n",
    "\n",
    "# New column by combination\n",
    "df[\"meaningless_column\"] = df[\"chlorides\"] + df[\"residual sugar\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data type to column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['color'] = df['color'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"meaningless_column\", \"color\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of a single row by idx\n",
    "df.iloc[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of a single by idx (different layout)\n",
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of a range of rows\n",
    "df[0:3]\n",
    "#df[3:]\n",
    "#df[:15]\n",
    "#df[-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by index\n",
    "df.loc[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For selection of columns there are two ways. When having a 'space' in a column name, only the second one is usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pH  # not possible for column names with spaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"pH\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"pH\", \"quality\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination for selecting rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:500, [\"pH\", \"quality\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions on dataframe, rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use conditions on dataframe\n",
    "df > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use conditions on columns/series\n",
    "df[\"pH\"] > 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean indexing / filtering\n",
    "Returns only rows when the condition is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"pH\"] > 3.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark\n",
    "There are much more operations you can think of (e.g. null-handling, joining, set single values, groupby....). At some point take your time to go through all points in the [pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html) to get an overview what is possible. There are plenty of examples! However, do not forget to just ask the community for your problem. For example search with google: _pandas add row to dataframe_. I am pretty sure that you will end up either in the correct paragraph in the documentation or with an answer on stackoverflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing pandas data structures from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both, `Series` and `DataFrames`, can be constructed from different kinds of input such as dictionaries, lists and ndarrays. \n",
    "\n",
    "First, we create a `Series` and a `DataFrame` manually to discuss the basic features. For the following examples of constructing `Series` and `DataFrames` we need the following lists and ndarrays of the same length as a basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Jon\", \"Tim\", \"Lisa\", \"Jan\", \"Mary\"]\n",
    "ages = np.random.randint(20, 30, 5)\n",
    "children = np.random.randint(0, 3, 5)\n",
    "cousins = np.random.randint(0, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here we use the [numpy.random](https://numpy.org/devdocs/reference/random/index.html) module to generate random numbers.\n",
    "\n",
    "Once again, in general you start from importing data directly into a DataFrame (e.g. with the above discussed csv import), instead creating it from scratch with building up `Series`. But at least once, you should go through it. In addition, at some later steps of data analysis you will see that it is good to know the basics. It will save you some time at a given timepoint, if you know the variaty and you are not dependet on external data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating  pandas.Series\n",
    "\n",
    "If `data` is an `ndarray`, `index` must be the same length as `data`. If no index is passed, one will be created having values `[0, ..., len(data) - 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data=ages)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data=ages, index=names)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can split the `pd.Series` in its two parts (`index` and `values`). Let's check the types and see what's [hiding as mentioned above](https://numpy.org/doc/1.18/reference/generated/numpy.ndarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index\n",
    "print(s.index)\n",
    "print(type(s.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values\n",
    "print(s.values)\n",
    "print(type(s.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pandas.DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construction from lists or arrays\n",
    "\n",
    "# Combine all lists\n",
    "data = np.array([names, ages, children]).transpose()\n",
    "part_data = np.array([ages, children]).transpose()\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame has a table-like structure, and is in many ways similar to a relational database table. In the example above, columns and rows are created with a default integer index and the given column names, respectively. The labels of the columns and rows (`index`) can be included during constructing or set afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index and column names after construction\n",
    "df.columns = [\"names\", \"ages\", \"children\"]\n",
    "df.set_index(\"names\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index and column names during construction\n",
    "df = pd.DataFrame(data=part_data, index=names, columns=[\"ages\", \"children\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct DataFram from dictionary\n",
    "data = {\"ages\": ages, \"children\": children, \"cousins\": cousins}\n",
    "\n",
    "df = pd.DataFrame(data=data, index=names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Data basics with Pandas\n",
    "\n",
    "Open exercise - try exploring the data set with pandas operations. Here are some ideas:\n",
    "\n",
    "- Get familiar with selecting columns and rows and try out different filtering with boolean indexing.\n",
    "- It is possible to sort not only by one column but you can set up a hierarchical order. Try it out!\n",
    "- Check the data type of each column?\n",
    "- Have a look at the quality column. Can you count how many wines exists for each quality level?\n",
    "- We have not discussed it so far but with `pandas.DataFrame` there comes [**groupby**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html), a really strong tool if you want to do operations or calculations on subsets of your data. Can you print out the first or last wine for each quality level?\n",
    "- Can you combine both data sets, red and white, to a single dataframe with an additional column for the wine colour, that you know what wine it is?\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINE_COLOR = \"white\"  # red\n",
    "df = pd.read_csv(f\"../.assets/data/winequality/{WINE_COLOR}.csv.zip\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get startet with your own data set\n",
    "\n",
    "You have your own data set on your machine (e.g. a csv file)? Feel free to upload the data to your workspace. But please keep it small. But do not use sensitive or safety-relevant data! \n",
    "\n",
    "- Open a new notebook\n",
    "- Import pandas\n",
    "- Upload data to your workspace\n",
    "- Start with your import\n",
    "\n",
    "You do not have any dataset? Have a look for an external one:\n",
    "- [UCI Machine Learning Reposity](https://archive.ics.uci.edu/ml/index.php)\n",
    "- [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright © 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
