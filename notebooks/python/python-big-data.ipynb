{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term **big data** is notoriously vague: How big exactly does data need to be to be big? Nobody can give an exact quantification. However, the term is also intentionally fluid: _Data is big if that it poses so far unseen challenges, hitting the limits of traditional data processing approaches._ And depending on what these traditional approaches are (spreadsheet applications, databases, ...), different organizations have different threshold of big data. Still almost all organizations are facing increasing amounts of valuable data and the need to analyze it.\n",
    "\n",
    "Throughout this course we have already worked on strategies to deal with big data. One consequence of hitting the limits of applications (like Excel) is to work with a programming language (like Python). After that, other strategies are open. In this chapter, we discuss the most important of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Performance Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` and `pandas` are Python libraries. They provide a Python API that is \"pythonic\" - that is, adhering to the style and principles that Python programmers appreciate about the language. However, they are only partly written in Python. In order to work efficiently with large amounts of data, their core data structures and algorithms are not implemented in Python but in lower-level languages, C and C++. These are **compiled languages** that are translated to machine code that is run directly by the CPU (**\"native code\"**), rather than **interpreted languages** where the code is executed by a program (the interpreter). Compiled languages often allow for performance tuning \"close to the metal\", but they also often require close attention to very technical details of programming - in this case we speak of a **low-level language**. A **high-level language** like Python provides many useful abstractions and checks that make life easier for the programmer. A price to pay for that is that Python programs are comparatively slow.\n",
    "\n",
    "But there are ways to get the best of both worlds: Moving only the parts of the code that need to be high-performance to a low-level language while keeping the parts facing the application developer high-level. Libraries like `numpy`, `pandas` and `sklearn` all follow this strategy, and using them allows us to develop in Python while getting the performance of native code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Python Loops vs Numpy Array Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = range(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 [i**2 for i in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = numpy.arange(int(1e6))\n",
    "%timeit -n 5 array**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming and tuning code for maximum performance is a task for specialist developers. Being interested in the application side, often the best bet is to look for a well-tested, well-tuned implementation of the algorithm we need in a library. \n",
    "\n",
    "In some remaining cases, we need to code our own algorithms and optimize them for performance. While this is beyond the scope of this course, tools like **[Cython](http://cython.org/)** allow us to do this while staying in the Python world as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Compiling Blocks of Code with Cython Cell Magic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(n):\n",
    "    return [i**2 for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 square(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def square_(int n):\n",
    "    return [i**2 for i in range(n)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 square_(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared-Memory Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For several years computers have not gotten more powerful by increasing the clock frequency of a single CPU cores, but by increasing the number of CPU cores. In order to take advantage of this, programmers need to parallelize computation among the cores of the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A powerful multicore **workstation** is a serious option to consider for solving big data tasks. Workstations with tens of cores and hundreds of GB RAM are available on-demand and at relatively low cost on several cloud computing platforms. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if a data set is so large that it cannot fit into the memory of a single machine? Nowadays it is common to collect and process many terabytes of data. In order to do this one needs to employ **distributed computing**, where **nodes** of a **cluster** work on a problem in **distributed parallelism**.\n",
    "\n",
    "The nodes are separate computers that do not access a common RAM, but exchanged via a network. A great advantage of distributed solutions is virtually unlimited **scalability**: While there is often a hard limit to the RAM that can be installed in a single machine, a cluster can be scaled up simply by adding more machines. \n",
    "\n",
    "On the other hand, distributed parallelism has a certain overhead in comparison with shared-memory parallelism.  While very fast networks exist for cluster computing, network communication can be much slower than accessing the RAM. Performance optimization in distributed computing needs to consider additional problems such as **partitioning**, that is, how to split the data and computation over the nodes of cluster to maximize performance. To put it in simplistic terms: Big data tasks do not run fast _just because_ you run them on a cluster. Getting optimal throughput requires careful engineering. \n",
    "\n",
    "**Distributed computing frameworks** or **engines** exist in order to support development of distributed programs. These frameworks take care of many of the raw technical details of programs running on a cluster. **_Apache Spark_** has recently grown in popularity. Spark is a general engine for distributed computation, with support for common tasks in data analysis. Spark is written in Scala, a language for the Java Virtual Machine, and provides APIs in Scala, Java and Python.\n",
    "\n",
    "[ðŸ““ Get started with PySpark: Spark Fundamentals](../spark/spark-fundamentals.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/c/c5/MEGWARE.CLIC.jpg) _Source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:MEGWARE.CLIC.jpg)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/). Copyright Â© 2018-2025 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
